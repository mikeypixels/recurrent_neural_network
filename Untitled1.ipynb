{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mikeypixels/recurrent_neural_network/blob/master/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTMJvROkQ633",
        "colab_type": "text"
      },
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQJjQFsNQ5RL",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZP9PavHmClrv",
        "colab_type": "code",
        "outputId": "ec8a0374-7b1c-437a-edfb-0a2df47b61cb",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "data = open('sampleFICT.txt', 'r').read()\n",
        "\n",
        "chars = list(set(data))\n",
        "data_size, vocab_size = len(data), len(chars)\n",
        "print ('data has %d chars, %d unique' % (data_size, vocab_size))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a7bc8bc4-c285-40a3-84a8-f94b8a6e3876\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-a7bc8bc4-c285-40a3-84a8-f94b8a6e3876\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving sampleFICT.txt to sampleFICT.txt\n",
            "data has 5196229 chars, 28 unique\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giDxncqARLu-",
        "colab_type": "text"
      },
      "source": [
        "# Calculate vocab size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SuBC7d7RWAu",
        "colab_type": "code",
        "outputId": "532e20f1-c54b-4e8f-cc24-e04f3f9f4fac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "char_to_ix = {ch:i for i, ch in enumerate(chars)}\n",
        "ix_to_char = {i:ch for i, ch in enumerate(chars)}\n",
        "print(char_to_ix)\n",
        "print(ix_to_char)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'q': 0, 'o': 1, 'w': 2, 'i': 3, 'g': 4, 'l': 5, 'b': 6, 'x': 7, 'z': 8, 'r': 9, 'j': 10, 'c': 11, ' ': 12, 'd': 13, 'e': 14, 's': 15, 'm': 16, 'h': 17, 'n': 18, 't': 19, '\\n': 20, 'k': 21, 'y': 22, 'p': 23, 'v': 24, 'a': 25, 'f': 26, 'u': 27}\n",
            "{0: 'q', 1: 'o', 2: 'w', 3: 'i', 4: 'g', 5: 'l', 6: 'b', 7: 'x', 8: 'z', 9: 'r', 10: 'j', 11: 'c', 12: ' ', 13: 'd', 14: 'e', 15: 's', 16: 'm', 17: 'h', 18: 'n', 19: 't', 20: '\\n', 21: 'k', 22: 'y', 23: 'p', 24: 'v', 25: 'a', 26: 'f', 27: 'u'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8gQSpJrTBAT",
        "colab_type": "code",
        "outputId": "0f243d7b-335a-4c90-a2fc-bd3f70cd419e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "vector_for_char_a = np.zeros((vocab_size, 1))\n",
        "vector_for_char_a[char_to_ix['a']] = 1\n",
        "print(vector_for_char_a.ravel())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwTBv2ITXxw3",
        "colab_type": "text"
      },
      "source": [
        "# Definition of the Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IBTwhlZX2PD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#hyperparameters\n",
        "\n",
        "hidden_size = 100\n",
        "seq_length = 25\n",
        "learning_rate = 1e-1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEXnQe13aeVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model parameters\n",
        "Wxh = np.random.randn(hidden_size, vocab_size) * 0.01 #input to hidden state\n",
        "Whh = np.random.randn(hidden_size, hidden_size) * 0.01 #input to hidden state\n",
        "Why = np.random.randn(vocab_size, hidden_size) * 0.01 #input to hidden state\n",
        "bh = np.zeros((hidden_size, 1))\n",
        "by = np.zeros((vocab_size, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l3_yUi3dTsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lossFun(inputs, targets, hprev):\n",
        "  \n",
        "  xs, hs, ys, ps = {}, {}, {}, {}\n",
        "  \n",
        "  hs[-1] = np.copy(hprev)\n",
        "  loss = 0\n",
        "  \n",
        "  #forward pass\n",
        "  for t in range(len(inputs)):\n",
        "    xs[t] = np.zeros((vocab_size, 1))\n",
        "    xs[t][inputs[t]] = 1\n",
        "    hs[t] = np.tanh(np.dot(Wxh, xs[t]) + np.dot(Whh, hs[t-1]) + bh) # hidden state\n",
        "    ys[t] = np.dot(Why, hs[t]) + by # unnormalized log probabilities for next chars\n",
        "    ps[t] = np.exp(ys[t]) / np.sum(np.exp(ys[t])) # probabilities for next chars\n",
        "    loss += -np.log(ps[t][targets[t],0]) # softmax\n",
        "  # backward pass: compute gradients going backwards\n",
        "  # initialize vectors for gradient values for each set of weights\n",
        "  dWxh, dWhh, dWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
        "  dbh, dby = np.zeros_like(bh), np.zeros_like(by)\n",
        "  dhnext = np.zeros_like(hs[0])\n",
        "  for t in reversed(range(len(inputs))):\n",
        "    #output probabilities\n",
        "    dy = np.copy(ps[t])\n",
        "    #derive out first gradient\n",
        "    dy[targets[t]] -= 1 # backdrop into y\n",
        "    #compute output gradient - output times hidden states\n",
        "    #When we apply the transpose weight matrix,\n",
        "    #we can think intuitively of this as moving the error\n",
        "    #through the network, giving us some sort of measure\n",
        "    #output gradient\n",
        "    dWhy += np.dot(dy, hs[t].T)\n",
        "    #derivative of output bias\n",
        "    dby += dy\n",
        "    #backpropagate!\n",
        "    dh = np.dot(Why.T, dy) + dhnext # backprop into h\n",
        "    dhraw = (1 - hs[t] * hs[t]) * dh\n",
        "    dbh += dhraw #derivative of hidden bias\n",
        "    dWxh += np.dot(dhraw, xs[t].T)\n",
        "    dWhh += np.dot(dhraw, hs[t-1].T)\n",
        "    dhnext = np.dot(Whh.T, dhraw)\n",
        "  for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n",
        "    np.clip(dparam, -5, 5, out=dparam) # clip to mitigate\n",
        "  return loss, dWxh, dWhh, dWhy, dbh, dby, hs[len(inputs)-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejmKHw4tvYEq",
        "colab_type": "text"
      },
      "source": [
        "# Create a sentence from a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqv4Hu7UvbQi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "11e72aab-3385-4ce0-8f13-b9cf87ef8fd5"
      },
      "source": [
        "#prediction one full forward pass\n",
        "def sample(h, seed_ix, n):\n",
        "  \"\"\"\n",
        "  sample a sequence of integers from the model\n",
        "  h is memory state, seed_ix is seed letter for first time\n",
        "  n is how many characters to predict\n",
        "  \"\"\"\n",
        "  \n",
        "  #create vector\n",
        "  x = np.zeros((vocab_size, 1))\n",
        "  #customize it for our seed char\n",
        "  x[seed_ix] = 1\n",
        "  #list to store generated chars\n",
        "  ixes = []\n",
        "  #for as many characters as we want to generate\n",
        "  for t in range(n):\n",
        "    #a hidden state at a given time step is a function\n",
        "    #of the input at the same time step modified by a weight\n",
        "    #added to the hidden state of the previous time step\n",
        "    #multiplied by its own hidden state to hidden state matrix\n",
        "    h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)\n",
        "    #compute output (unnormalised)\n",
        "    y = np.dot(Why, h) + by\n",
        "    ## probabilities for next chars\n",
        "    p = np.exp(y) / np.sum(np.exp(y))\n",
        "    #pick one with the highest probability\n",
        "    ix = np.random.choice(range(vocab_size), p=p.ravel())\n",
        "    #create a vector\n",
        "    x = np.zeros((vocab_size, 1))\n",
        "    #customize it for the predicted char\n",
        "    x[ix] = 1\n",
        "    #add it to the list \n",
        "    ixes.append(ix)\n",
        "    \n",
        "  txt = ''.join(ix_to_char[ix] for ix in ixes)\n",
        "  print ('----\\n %s \\n----' % (txt, ))\n",
        "hprev = np.zeros((hidden_size, 1)) # reset RNN memory\n",
        "#predict the 200 next characters given 'a'\n",
        "sample(hprev, char_to_ix['a'], 200)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----\n",
            " haajzjzpzexpokrqitkrzrrzaiaal\n",
            "qxtjjojcxsoaojtrxnlxvcr zbayfm\n",
            "fsutclthshteywartvvmbqhvsqbmjzzthasezgs\n",
            "zy\n",
            "kuzujhzcqrprp\n",
            "iiabeydlhvbdfqqiht vysmsyxkvyjlgovmzlkbsvh jloemwgvw\n",
            "tiht\n",
            "wxzbvplsneot fffdojzghtt \n",
            "----\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmW1rudr22LK",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4WGKRi00Uaa",
        "colab_type": "text"
      },
      "source": [
        "## Feed the loss function with inputs and targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxL6yZJ50ZTL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "745ca960-c9ea-4739-f64e-a707ee84cc79"
      },
      "source": [
        "p = 0\n",
        "inputs = [char_to_ix[ch] for ch in data[p:p+seq_length]]\n",
        "print(\"inputs\", inputs)\n",
        "targets = [char_to_ix[ch] for ch in data[p+1:p+seq_length+1]]\n",
        "print(\"targets\", targets)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inputs [2, 25, 15, 12, 1, 18, 5, 22, 12, 6, 22, 12, 9, 14, 19, 9, 1, 15, 23, 14, 11, 19, 12, 22, 1]\n",
            "targets [25, 15, 12, 1, 18, 5, 22, 12, 6, 22, 12, 9, 14, 19, 9, 1, 15, 23, 14, 11, 19, 12, 22, 1, 27]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qirsQxEt2Tih",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f06020dc-5add-4f7a-a209-0442af21e70e"
      },
      "source": [
        "n, p = 0, 0\n",
        "mWxh, mWhh, mWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
        "mbh, mby = np.zeros_like(bh), np.zeros_like(by) # memory variable\n",
        "smooth_loss = -np.log(1.0/vocab_size)*seq_length # loss at iteration\n",
        "while n <= 1000*100:\n",
        "  # prepare inputs (we're sweeping from left to right in steps)\n",
        "  # check \"How to feed the loss function to see how this part works\"\n",
        "  if p+seq_length+1 >= len(data) or n == 0:\n",
        "    hprev = np.zeros((hidden_size, 1)) # reset RNN memory\n",
        "    p = 0 # go from start of data\n",
        "  inputs = [char_to_ix[ch] for ch in data[p:p+seq_length]]\n",
        "  targets = [char_to_ix[ch] for ch in data[p+1:p+seq_length+1]]\n",
        "  \n",
        "  # forward seq_length characters through the net and fetch gradient\n",
        "  loss, dWxh, dWhh, dWhy, dbh, dby, hprev = lossFun(inputs, targets, hprev)\n",
        "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "  \n",
        "  # sample from the model now and then\n",
        "  if n % 1000 == 0:\n",
        "    print('iter %d, loss: %f' % (n, smooth_loss)) # print progress\n",
        "    sample(hprev, inputs[0], 200)\n",
        "    \n",
        "  # perform parameter update with Adagrad\n",
        "  for param, dparam, mem in zip([Wxh, Whh, Why, bh, by],\n",
        "                                [dWxh, dWhh, dWhy, dbh, dby],\n",
        "                                [mWxh, mWhh, mWhy, mbh, mby]):\n",
        "    mem += dparam * dparam\n",
        "    param += -learning_rate * dparam / np.sqrt(mem + 1e-8) \n",
        "    \n",
        "  p += seq_length # move data pointer\n",
        "  n += 1 # iteration counter"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter 0, loss: 83.305115\n",
            "----\n",
            " siqpnrvzlmljazpczjpu\n",
            "o\n",
            "wjriubtkcnifprhcwnkilnbmbbfkclyrmamauesofccdrqzdxtdlmhtvwsotpfatav kwqyzbgn\n",
            "c dlrgtpxkyw kxjdgdxadvdkhuuuphseaecuapunfaclszunoeorvvxucpi zcxekjutjrjxu iq\n",
            "akt\n",
            "ihl\n",
            "bcfa\n",
            "entijkyxfx \n",
            "----\n",
            "iter 1000, loss: 72.632768\n",
            "----\n",
            " the at fitienpeke wos hucloeg popdin teininornud voran oniy donecad arrcee honry an vee to epitactlorpe iyi at un hrocptan at ot hleitanrens avt wresrin ref held hhirealoyshnnare th uy sifo sr hiads p \n",
            "----\n",
            "iter 2000, loss: 64.894428\n",
            "----\n",
            " e therleas miranord asle wely ender crot an antith opran pfand ope ardsed wen tit nfaune pdirtd toirh med thel ingnythitrers bpaswmonye is honl in titd wee dyeme in beof ple sibiny ar to an pettres th \n",
            "----\n",
            "iter 3000, loss: 60.427078\n",
            "----\n",
            " nt bare of ar ost hicemaqunt wometce tengrithumasu an ufilise pof hasitheud the athe pceaage intich aokeg liwe inind they tiredt bot oy gasp ance cforotuuud ancuth tislende thy htibantba inceuedif tef \n",
            "----\n",
            "iter 4000, loss: 57.852652\n",
            "----\n",
            " s honyt of cok tpop angs af deerof byorep in soedtenlettelad thes ote tome naly younteeswamirn wice auen oh sfeuw alet ane sithen on cotuc ad ononliby m ttobiteulm pos eras whot ciiny ag onnpe hadser  \n",
            "----\n",
            "iter 5000, loss: 56.537859\n",
            "----\n",
            " merliet tulleed avass i hart pleegle fuld mis oxnou go fasmanq exmers heleve in mart extribf whid sos awt ares covag wicg aenctpor in bouusd ste sher thecesvis asws ceculesef \n",
            "rorescheul hey nand ttel \n",
            "----\n",
            "iter 6000, loss: 55.457779\n",
            "----\n",
            "  tound tans incet ond igmedovy al beg stot lopej ug of th peros ald dete fit of gjoye mas a po somy oh ae fot jur a heruum dewf dith hime weadint sedscious lo fagh wein tholy hirpit ur wemhengus thouc \n",
            "----\n",
            "iter 7000, loss: 54.662128\n",
            "----\n",
            "  wing arben stand ergy jouviche anglief ans ig abed fourtof guy errll kois ad thebd a fouecs irsders to bes in bedred he thomnonqur merepad no thas a pead dreartilase acker asion and iusit hy wound mo \n",
            "----\n",
            "iter 8000, loss: 53.922049\n",
            "----\n",
            " nt tajedtre fige teicanm thith evarce in wence los the in uy thon whave i prits a thar hutt ansele do tbee sheve shanels thadevee cortuins cat wus acen japree obstinf athes crof the efres of coupe shl \n",
            "----\n",
            "iter 9000, loss: 53.867494\n",
            "----\n",
            " o kome will hespieder peakr hens the aifny cemision en is the fod aege iwigersely ancend the ncelio nhatt yist masts k wang vok a he thel m hipithive hintent i to chath the besen is ald theper a mo he \n",
            "----\n",
            "iter 10000, loss: 54.025549\n",
            "----\n",
            " l whatin the i frighey hhe betlllirets ated walriof baac an dealct touncmswiwe gemrestesfis monccer hukl it waassawerly anguty ther baten i pocle lemly bive the kitpets thes sererertenllev round anvem \n",
            "----\n",
            "iter 11000, loss: 53.552464\n",
            "----\n",
            " ck viak whive pomathe clatnlme cancarjerlant thricl ny bos the bees themunt the brily moce sithing aedingpioud the a fomis hatithe in the ount lray burwis i ed u tiin sor gerougly bot heobd bleme eve  \n",
            "----\n",
            "iter 12000, loss: 52.758811\n",
            "----\n",
            " nged renegrict wisn soptret that che on her to tis was and asfuld led the grimn sen sheinigh foover veree we chout yhe heand theshey ptars mang rail in pefred of foum tweanong ho wuch oigh yom sis wy  \n",
            "----\n",
            "iter 13000, loss: 52.820721\n",
            "----\n",
            " io the blewe cecrer hed in thess out ast ca and bu not tues hes bsold reatent ret alef cord hing ands wiss micpavimgucrinptanguly yopeve pancimile a it hork coics swer wow of wighond ypapto thoce susd \n",
            "----\n",
            "iter 14000, loss: 52.435064\n",
            "----\n",
            " thit in seir you thoulewensiss minvime ae the ry spausterning ne shee forting mithing of hist ouck ined moned nornivn dersteilitut fas ching weld be iens waghere withies fer bror yo waren and she s an \n",
            "----\n",
            "iter 15000, loss: 52.242908\n",
            "----\n",
            "  hiltionf rand inmiof trist hes plead woof i hitkieb in sute ad fond nooebo llo ked i gage ptelied nile fuca haak ow of hus me rean the bnes coud miditg shadd amedirr a her as kepling ppadety buil cor \n",
            "----\n",
            "iter 16000, loss: 52.203055\n",
            "----\n",
            " e jurt cowai picelliog s sing co werlenss broulndid hover prennthiteder of chel on of was tol he ot busilty hoof kistarriner wald to bu cenpron more lo deisw wan a srisken miges hhard ly sery the urne \n",
            "----\n",
            "iter 17000, loss: 51.418771\n",
            "----\n",
            " oney his touty i id and gourese tos the lund over in hinded sicln on tict ltrallly a exay to stond the what singed beowy any gornou of he as a ang ane ated harer gist a nss wared at the mour ongy ghar \n",
            "----\n",
            "iter 18000, loss: 50.856731\n",
            "----\n",
            " oor inl shen hace lllyous go ayou artoun i s oung tras herrounsifd a de yoo sue andtead thads ngithelangide who dy leme and a cere ro of aqued hin thald ched her the i ceir her and wald it whapes a yo \n",
            "----\n",
            "iter 19000, loss: 51.143330\n",
            "----\n",
            " more my thoud koost and i fayome to wouc sforl fics anss ats tomfay the mehs of biver sayse i hust thot new to her leacciea zivithire scided that nee he vore i pnendon me torave that loredy me kucts f \n",
            "----\n",
            "iter 20000, loss: 51.335067\n",
            "----\n",
            " y were for o mpeally on new woremuing stay on hek bren miwh ly gurn has is the coumh od s be wery mleety thildeps hercimeade bercelp ae so vad toll sras beel of to math cank much uglon thand cout dosi \n",
            "----\n",
            "iter 21000, loss: 51.047526\n",
            "----\n",
            "  you of to soror wititked in andoll sory gee coule vefe wise soscnous a bulltine i boved in beowp a toat i le in i woud regidong foter guscrel had heat fargbenn wpepmare forer that he dus so le ams th \n",
            "----\n",
            "iter 22000, loss: 50.637776\n",
            "----\n",
            " thoupe and a gentha\n",
            "ed yousted inssyou her ltrithe now mim witt hely wour hing muncuptritt hathe fo you sfoted hore hearlidg inis he sfatian week if lot bof iebon the beak bount werg the zuaclerevidis \n",
            "----\n",
            "iter 23000, loss: 50.311851\n",
            "----\n",
            " upelied fancitheld ky weit thingerinicas thebe annly rave wis wes havisule mancisw i crittien toless the mrirenss cxtuckning son milo touglive tut wated lofan ankfareaurl he hisphe gephimne the trerer \n",
            "----\n",
            "iter 24000, loss: 50.985098\n",
            "----\n",
            "  when elle in therce efoue yon taol mut thesen cent houle sint chat at correat whoin mliniskerelumline mind nomane hayfere ghiched be on fruct d cernes nitham ain in witijus whas on they nep re the fo \n",
            "----\n",
            "iter 25000, loss: 51.223955\n",
            "----\n",
            " tow has ttey othe whun pome the a less and prysanttencu stion on ohtime wouint souf hade itemerisile ang tiasalbeve sistey ther one thkid wis edenteyser werivegen he sead tho couph a ictt me of she ho \n",
            "----\n",
            "iter 26000, loss: 50.488730\n",
            "----\n",
            "  ganging tpo thee and in in aps mrail shis thand courd corons no ladsinishey sid head in nouk lean tarttoup leswinf eralr was i re ard pureens ns hink then fatet a ed the kuss gred liwer rackaping the \n",
            "----\n",
            "iter 27000, loss: 50.607497\n",
            "----\n",
            " d bice hhat of sto a the sunktres to amt thonp waid ham ouin demby tills me bes soup clow fomancish dlonk watsor it withor me noutturoon mole kell dired hidl it on we prowh squck fout of fotedos lloch \n",
            "----\n",
            "iter 28000, loss: 51.701949\n",
            "----\n",
            " mt i no shurste im nnoupnis on to the barbat fack fads a moong asw to with creld bundled jo nich rerlit cito he he farowe fottimillalle ary thae d bisk lare anctabp was if a the tewisp yowin a saogh s \n",
            "----\n",
            "iter 29000, loss: 51.096877\n",
            "----\n",
            " at hourd no bear theng gased the it kealof baegws an in he case htru raglougangispele her ouss ane silly nelion find cackel teile ther parainidad nowy and tid wighe by nothe me gnatseriban be ting the \n",
            "----\n",
            "iter 30000, loss: 50.272119\n",
            "----\n",
            "  whey and fuin lests by was dratane and nom flikg lount fotht cas on to were dtheer and the at the shem it low ams and ap inlied ligomed ast cous morit hithing iching of tare no dist thered the sore i \n",
            "----\n",
            "iter 31000, loss: 49.887028\n",
            "----\n",
            " le ih sis pirile tabee shein deway the be and hidser the piss shy ale a frencaranly hand buthire hemed ohmthe chlins yef ondreate dee ciest reme dinder he brencaed not bow andible fan he ather maal at \n",
            "----\n",
            "iter 32000, loss: 50.503523\n",
            "----\n",
            " fomarnen a paevive be conchand sunmele of cour onemirupely ofon ondistso forly nilungole gentitt itty hame have felds of thonlathed ene on teethond ineded sack ting ay outousmealunge we ad wo henting  \n",
            "----\n",
            "iter 33000, loss: 50.608729\n",
            "----\n",
            " ang soon thear hesintsand hewe belry abroll loprere the jadis of of a lition ghe lavan anjugh semist fat rlomkelr mung le was his fils thit haiighitas of cos oulfurld apdle fur asted sfovit ardoransti \n",
            "----\n",
            "iter 34000, loss: 50.437212\n",
            "----\n",
            " nt eom has che srish pliien the rasile his prow ad exhp tossouprold tece of shee disrweliey votruidites and it cat wisist core blood ho ho wall andion plis yourly bunges come to you suid tseald bage b \n",
            "----\n",
            "iter 35000, loss: 50.238837\n",
            "----\n",
            "  sulled oxsee was be un perned autry fartike cat rishall bor llangrend perolan foust hachinged has blo gome parr deremain has heress cans wa heir so houd i the of ancan nom of whold sait oce not basti \n",
            "----\n",
            "iter 36000, loss: 50.023704\n",
            "----\n",
            "  sfitt ofs beanmi malding tiss intedty ghey to up tigher tus winc of thalver loved the risting the ore cour the fropenldilt the kytselbatacts in a yood and pear bee miras meniif the rensont apss repes \n",
            "----\n",
            "iter 37000, loss: 50.048885\n",
            "----\n",
            " he poom twid by bumesqusire bacwes nourongalleluteluin i poule he uscough them youst it ankids at the cis hom ack the bearae thirt a prot his mechllang theimpaod the movion atc staalloseder ince asnde \n",
            "----\n",
            "iter 38000, loss: 50.403059\n",
            "----\n",
            " a arcus thly thess sins the ge tomandey to coulteding enias utlasct musperopens of becemor hoopens stilnent i munkte the was a as and noteen werued to do whole thorse ur couks trechtelded flimuts repa \n",
            "----\n",
            "iter 39000, loss: 50.250635\n",
            "----\n",
            " e lisemar revellins shousseri ald she gearon be and onaved tity urd owth thit falen the or bot in and avery und thim builunest ofnuppo ind it in and bed purce mligh anduln a macare the fadlint the exc \n",
            "----\n",
            "iter 40000, loss: 49.750985\n",
            "----\n",
            " n his tay agamby ghe mdire bey hes thes hat besttre meting weeth and ose veled aole ind it met atce the her in lists the ext me envore hon be and thes forld belre on thiy llangecty oht the lance on on \n",
            "----\n",
            "iter 41000, loss: 49.909029\n",
            "----\n",
            " in mrian fyncocrele fas atief has miking eptonich had couk us mir bed laish alf hussle eaclund ateeting so bos iver as outher ae butermiale was ston fere ulo derow to a lakth thato hoolb surneded the  \n",
            "----\n",
            "iter 42000, loss: 49.226635\n",
            "----\n",
            " wither it whansaedy be chared a jod the umy futcaly are sack inove cad the foumilied noted no all ane heven and be rewey pood cu pre beatin hing tarte hit the ronss and ier ting horins wifm be the sto \n",
            "----\n",
            "iter 43000, loss: 49.359608\n",
            "----\n",
            " ite toone y the dest fit ang poftroir beane in he poleisd and wing motaices ccont whas pis who to fant of pliving ane who on a spaytueve sadgen with have seaved matlyeciech sime stonctile in wheaps in \n",
            "----\n",
            "iter 44000, loss: 49.400461\n",
            "----\n",
            " d ohe noston laftunte she lefine his ult faod hhithe yob brall saors suvecutiter the ars had the spopto chere me iny of aut and moun of wabe them pand yhes blod onon apding gerimureelt thearned hey ha \n",
            "----\n",
            "iter 45000, loss: 49.765082\n",
            "----\n",
            " thissenire at one me and ohteding wich tntther rotce isd tuefsterry bay at thencouking a sumsy lanse that forliece shurl fering himbin the at fimea the bowt yrearilemest rrond a befted repatily that r \n",
            "----\n",
            "iter 46000, loss: 49.667444\n",
            "----\n",
            "  the hithead this a boting ting i seaboow a mal my inan at aid and muam shat brobeerer suconmfely ciod touckstint ame sould and of that the soruty dus aumir sotrind but mirohed toon to browen tat me t \n",
            "----\n",
            "iter 47000, loss: 49.161892\n",
            "----\n",
            " ve reupilmoupaled helreas and pagk on indere fren the gounty breadfirestry iston and chily hon a a blostry alk and and rut werl so corl undlakinged a lectine wey ols ie the wat oupicitit\n",
            "and for dodli \n",
            "----\n",
            "iter 48000, loss: 49.328391\n",
            "----\n",
            " y ancurascted chire whimhif mucon sfarmenkers of inly the lllistoun the els in wither salded she the hough the toming mont hirge pixty the a fu ghat wounsond brizbo his of afseen the wigh atcor i pour \n",
            "----\n",
            "iter 49000, loss: 48.883039\n",
            "----\n",
            " we the toot mided or haveel the corond vis to as critent his of the erko fiftn ky we olensy the heid buter grous asceults wich gomally the deakis oxcail it to sucked ro hithe tral barn poudarly tretna \n",
            "----\n",
            "iter 50000, loss: 49.190026\n",
            "----\n",
            " d you him the prats as a of wather heare beante the nots of a grame plave couth dos clians yor hue dilm sound serther deming to to cropend a inong thepe thes fell lworkerson to in suss ry ave mrjed th \n",
            "----\n",
            "iter 51000, loss: 49.087840\n",
            "----\n",
            " r of agany the eavinatting wanlsaterny clion the momh the of erstever the listted ere whas uthand neadeolled weat laatenog as to thestionnoth ke deort the you stelot sigher i hachon fare that tho wis  \n",
            "----\n",
            "iter 52000, loss: 48.841431\n",
            "----\n",
            " r her chadedy the hard loch dag sting som geesist lewasge exish dough her her intto chiincer wopare peare hero fal rottathel has the prant whem and was andos and sootny witr poked ongarf the prither m \n",
            "----\n",
            "iter 53000, loss: 49.024976\n",
            "----\n",
            " erell timent reqluth he sermumusarg losstentmint me sher ted chonk incestto bain hher gyore yoy the galk wast noce catted a bey sting in bo cooxan to mome whime an wes insidaty gand a his be huppertic \n",
            "----\n",
            "iter 54000, loss: 48.856613\n",
            "----\n",
            " eem sur waid isced asseint be on tfaid werist paje fok freold amink res the her and apbion the ban whisher to eny beaks he him be cao had a ancl of thow proy vind sten fer of dagider by if gell aise h \n",
            "----\n",
            "iter 55000, loss: 48.999184\n",
            "----\n",
            " m a roprerow shise milm gile saie hell tanticeof enterit neld a joulls as ryo frey the fare woh the mphen your neiling tourd had derilizintance a fle of with seroor by the raydestroll thilling at de w \n",
            "----\n",
            "iter 56000, loss: 48.790613\n",
            "----\n",
            " f brohmunderous the nofeused a shin dey on the hostelirise recaod the all nise eburtely mingt fath bais lorioun whough youns aeded fore de throquour siveray las haboten ard so memenn palat in to fing  \n",
            "----\n",
            "iter 57000, loss: 48.873242\n",
            "----\n",
            " ato day shouk wis myed deromssoss ay the qucilile thim de foron reath inon with have geres spedo pocty with thel mgpeinch dlornd fpuededras livey i muads hem the clestiont his suews hith and and mire  \n",
            "----\n",
            "iter 58000, loss: 48.443581\n",
            "----\n",
            " r a surshijure i de farly of the ppowing itrom the king risdelled appendent tily be grough what with hiu shot they sharet at shads the horep anicur huptat mise thed the by as whee ss threrle mals care \n",
            "----\n",
            "iter 59000, loss: 48.859736\n",
            "----\n",
            " sed the it he matis a itelinist dous to it whantey youp cawin rough thecr the was hoce ross aghanged ngar syom nalmo abes it as leen not lare of thined in and with tong hit frow mrechiin it mly teren  \n",
            "----\n",
            "iter 60000, loss: 49.135502\n",
            "----\n",
            " and pats efioun coin weas stervitulf rach thes thak s gell the ere tims haveft in\n",
            "hell toortine tromesing gror stoonet whald allist wantus the and rliif the thetees ho hait own kequater rich olly her  \n",
            "----\n",
            "iter 61000, loss: 48.397440\n",
            "----\n",
            "  they andon i evem un whitase matan ther gard the and trare you love theing on wiatick monddenciccibed corte diwh jeccorting he is tald eghime non ineaxlen ary by wim she orer ases whit astle gfnatiin \n",
            "----\n",
            "iter 62000, loss: 48.981430\n",
            "----\n",
            " ef of he thly chorl of fuch amceging gre a sto in upore be whais and maong sild whing yor elictbon in ricl mave at depall ecear tristilrincouthece neavingld up mnoart tin the ouf insaltt the and las i \n",
            "----\n",
            "iter 63000, loss: 49.117080\n",
            "----\n",
            "  on mimoell furion ealt i wigh mo eling it ancoeks so and duirst reat om of scoreiling for quet dotton thesttan har itulinous in to blabomy thee a warce dieres and with preas heoss red cous surt kling \n",
            "----\n",
            "iter 64000, loss: 49.143874\n",
            "----\n",
            " em in to diese he flanding coughan wo fime mider had has outh werraid bronter o the ane muth clede nepes marsturd to once fokny his faldy ssmicked stomuld have infey the mu then be braice he wes shoul \n",
            "----\n",
            "iter 65000, loss: 50.566485\n",
            "----\n",
            " ol at deque frale molm dinta s wherieds liggey dyees the yyar a in like tin ging ar bvy hes pacied would bifuan wane whe aparesant sorusy asqued these you him he fupther bartn cowe of bultas savequade \n",
            "----\n",
            "iter 66000, loss: 49.861217\n",
            "----\n",
            " ighriegh as deaterweted upem to rveilascire sith the geploded smoks arsns in muphed bessing ay cwaboth ge am neparitt o wengand pcoms gion lat ay the onveeelt amulple ouil and gone to andigran cempupa \n",
            "----\n",
            "iter 67000, loss: 49.869168\n",
            "----\n",
            "  to to ap of a tabed they i the nigh wwo fry eoskarser matsen glent waz chich mut heanded in ist armonagibent hard ele wing dew she deothern plliet hivt the to ke treitifh on noor and the nofy that ab \n",
            "----\n",
            "iter 68000, loss: 49.076609\n",
            "----\n",
            " ory ms fondieg stired hacked coht brond or elort an the spund htrrendall the youd to otheer dads sess or of in s wit reriend is loin is orch wichen lithing and in and wes kiss as my the cenle here lan \n",
            "----\n",
            "iter 69000, loss: 48.916504\n",
            "----\n",
            " flouldinglinkiverg wabluranes shat tha muround the fon a eveufly dighand you as bere me is oldom ouls protoovem trenthan broutont af in in the tilg dided narded inon soce ruts bed laith bicanca powpe  \n",
            "----\n",
            "iter 70000, loss: 48.456842\n",
            "----\n",
            " face rexkins of hach you hus and phanthy worgen strufeent on you went gilk nevancher over of contat ed padintt thith and his forn rucuiten her cherny had low ting him go destreidund hach bell them le  \n",
            "----\n",
            "iter 71000, loss: 49.058829\n",
            "----\n",
            " inder un worce the hr shubgen he s thing tath youln put speovessry bivor sise sfly ejoogsy hive had gangurenss soo it ansiun teroand bilikingsned to thilll frersitenzith cat sosby southiruplion manch  \n",
            "----\n",
            "iter 72000, loss: 48.576819\n",
            "----\n",
            " ave lequad afally sery to bidarowing he tance graning gucked on at astuend ict sestevar it wome shel and core of roppathar mute the loodsoen to whings esigny thus abay him it that tosser and treapt on \n",
            "----\n",
            "iter 73000, loss: 49.078664\n",
            "----\n",
            " n quibuldarg heve in suction that wat supl u faz for dirgher serove on she xay is of the bild and his afro therd dibiughine the to he cros irersirather thes if a satt bestes abens the prene the then p \n",
            "----\n",
            "iter 74000, loss: 48.595811\n",
            "----\n",
            "  bein the with ontarg this agealdy bal fas then tifaco waglaritire have lavenaretly and tion to that shonkle in the shillan stananed thes he for stouk his waly the deas ayst ham ther acltentues grarge \n",
            "----\n",
            "iter 75000, loss: 48.536269\n",
            "----\n",
            " s her ibellocied fourd hild it beveas goul of the toaked rewen the filongn of hees to the lo you nifurviching i yane intherion woment ardon whorning lacheer a dive sfore be bothtielding sered the inca \n",
            "----\n",
            "iter 76000, loss: 48.700315\n",
            "----\n",
            "  leyter dfnen that ankyor and ratint afs withor fourd and fol fosides laithered to at i med a offen hhe you and tatowh you of rarm cith flo come noousieoss on and the sishey whee ang the day with so m \n",
            "----\n",
            "iter 77000, loss: 48.344812\n",
            "----\n",
            " greas the mat his to pem riry patisame he wese giventar the lokern wht cig srow dowged jagease nay the gevathich de ief cose sertt s banice hous crutitn i exfoneny insn beitson surly in been afming sh \n",
            "----\n",
            "iter 78000, loss: 48.314862\n",
            "----\n",
            " gited or to quath of itane save to lecpurianten aniwe inca to cull cat it thind buld andon his who in megrever ases up and serenn blaby fastton shey on fope twade waples cricempi gor ak filled of a th \n",
            "----\n",
            "iter 79000, loss: 48.475949\n",
            "----\n",
            " ole samuncens buthen yo bew ane widdinoud ecille rapare atjor a langged hergs ane be to whing mildor a more ane the ofrects lad was wis costerever as saw ant to exaroun he floise the netse tont browne \n",
            "----\n",
            "iter 80000, loss: 47.832663\n",
            "----\n",
            " ul have dlal i hour coute wit bect and the spand char ast the spustries on a ploeds he pat surt the wongret poving ciny in heap vimily for in tcay till jutt ol that his optureng losrine you tonern mal \n",
            "----\n",
            "iter 81000, loss: 47.612585\n",
            "----\n",
            "  quelcibutary s and aswereblint his pray in that eet his munder she everfartom rephave do inge the ornighetrunss me minged raich and yoush pursided his whook i sus i the rew were fresens thiched eves  \n",
            "----\n",
            "iter 82000, loss: 47.659115\n",
            "----\n",
            " ervile uno have the but the lo fyend ul soncile aupionder ntend and butth ol a agimy it hat nighen in to worlido cort a sers a laise prom linitneaditestint luid and the pevent it byer stry the and fid \n",
            "----\n",
            "iter 83000, loss: 48.603318\n",
            "----\n",
            " ngelighe raged vainent susting diversont copdly the bo itnes ims aly sear to mint i bro chare afed is weer in no hagkiton than was i oh to padly seely avey i carever a lis laiter whurd ithoul inon was \n",
            "----\n",
            "iter 84000, loss: 48.486272\n",
            "----\n",
            " r no it mines or the lave hhilbngethry his had be it one my clinthion prept the dackny trovel liegh you their my a then and lowh om of lidg mather then sadsal if if his elay and hay thy frenst the mal \n",
            "----\n",
            "iter 85000, loss: 47.723013\n",
            "----\n",
            " o ds whill prent sohhill dood them he cast latient bume indwesen the rephire thell imun disted ling flell you if or i mastras hre abo s the ondinednidep he goned the exhe bey a vighlowten restmold mal \n",
            "----\n",
            "iter 86000, loss: 47.707644\n",
            "----\n",
            " anday of in then we be amure as and it the exfost cay hipcly the plith dut less in hromed marcold to moronk ass lain pant yor inther dewte sloodly the ond thourso kngeind ousens this pay then wopkins  \n",
            "----\n",
            "iter 87000, loss: 47.919282\n",
            "----\n",
            " we has to call coneath of theyere nese ca clut not from thet is are not cho hored ark at yther were wombling sfaigson auftanor the pese it the fars in cased fukbed a hers efountiencult reall whath was \n",
            "----\n",
            "iter 88000, loss: 47.960570\n",
            "----\n",
            " iigh if xves weund lot wryow omburicat lact the sabol whings of to beor ce a larat that oneus wheardor unkud serever nencery un in filloa grone tulls would i mes lonss alzny whimssre was in hed bycort \n",
            "----\n",
            "iter 89000, loss: 49.149775\n",
            "----\n",
            " rs are plee mey wherom githorssion and ot ase iwf shiriece thet anishibl oud he worly dokeng in owy so eltatssey is a wtien rest as whoughte sull alpee to to angress it tell were bot the baar so sume  \n",
            "----\n",
            "iter 90000, loss: 48.444908\n",
            "----\n",
            " if for new you wemens reay ars thear threy shantranwertly blood le islexcendex bearther babgy the but me excrese now med wise new gy cood debelle thoubty cat to ham myheit miveds has whope ust that i  \n",
            "----\n",
            "iter 91000, loss: 47.489545\n",
            "----\n",
            " prerked getle a kined exrellow emped elourtni lly a proment to vert i that unl lorkely the me lonenyws had anded to aful has hiph is araci angs youn heesergo ssess in outlnever groong this whealdred p \n",
            "----\n",
            "iter 92000, loss: 47.293680\n",
            "----\n",
            " ad op the unduputy these trom are teke gle i boter the ping buikile mive sowissed to and in it gome the welds a a trome y to co enierser thiy tane me and faly the daid wis legriitul to it bland hohpre \n",
            "----\n",
            "iter 93000, loss: 47.123735\n",
            "----\n",
            " uroaserly ousled net seret thonding lighn if se wibn his the cow we vay fning sige timensered or but he worrned was fation of his krom saike laiker rewed we gurere a hind tabulth sernas mated mllinidi \n",
            "----\n",
            "iter 94000, loss: 47.540008\n",
            "----\n",
            "  siggo her wetolled in\n",
            "aly nath a dugkank say pat the epigh a an reor if her bover of liont lup of that the gut adaund of que tury wis they here at and his n the ant overavece in re lemed laeseyts ten \n",
            "----\n",
            "iter 95000, loss: 47.751578\n",
            "----\n",
            " stown blo groms nes ubou wis the the reat the potrestuss he writer anening all one perither s mide she styoutonithis in wont it treakiwn abay fabed that to s is a nowle of to has and so jout he phere  \n",
            "----\n",
            "iter 96000, loss: 48.712468\n",
            "----\n",
            " all woun otilonn nep anedy liggs mome avz uprey to hous he and buch drilogg spess her ppald hen the cand buse and bot bendinion eveactiche bowejeseated the s wo mnyy eaps theely s beme el joty ret i v \n",
            "----\n",
            "iter 97000, loss: 48.347161\n",
            "----\n",
            " etied says the tive chere atrars of you ofttuth inlie coonss hert obon it githrand it fad say sess the gon heer they inspin to he srors rees clodlnose how moned greety forey reare as hamsegion tllieng \n",
            "----\n",
            "iter 98000, loss: 48.125463\n",
            "----\n",
            "  pume searews kienter and of and was houl whess same they would a and lowent anded plertood dent they sed weld had thy averuld hump and upon to heirstmand laid yaun o\n",
            "vemoling ked suraur a woull amead \n",
            "----\n",
            "iter 99000, loss: 47.475933\n",
            "----\n",
            " t athouks fok at in it as intousury i that by to whonose lantacouble that luin sest at fol hould broit she farared with bon to said hencr werridriwsed mangever and thes one terent bettrey yand and the \n",
            "----\n",
            "iter 100000, loss: 47.283183\n",
            "----\n",
            " w a sied lokn fouldle ay said and hyaw lould in diem it in i a chre nop and at woull grat exces wher che ned yyoug he haves he tlis coouss ad nouh oked yens in frake and it the romied breargon hatever \n",
            "----\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}